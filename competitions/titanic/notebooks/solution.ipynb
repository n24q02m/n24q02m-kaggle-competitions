{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Titanic - Machine Learning from Disaster\n",
                "\n",
                "Competition: https://www.kaggle.com/c/titanic\n",
                "\n",
                "**Notebook này được thiết kế để chạy trên:**\n",
                "- Local (VS Code với conda env `kaggle-competitions`)\n",
                "- Google Colab\n",
                "- Kaggle Kernels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Bootstrap - Environment Setup\n",
                "\n",
                "Cell này tự động phát hiện và cấu hình môi trường (local/colab/kaggle)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === BOOTSTRAP CELL - UNIVERSAL SETUP ===\n",
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# GitHub configuration\n",
                "GITHUB_USER = \"n24q02m\"\n",
                "REPO_NAME = \"n24q02m-kaggle-competitions\"\n",
                "BRANCH = \"main\"\n",
                "\n",
                "# Detect environment\n",
                "def detect_env():\n",
                "    if 'google.colab' in sys.modules:\n",
                "        return 'colab'\n",
                "    elif 'kaggle_web_client' in sys.modules or os.path.exists('/kaggle'):\n",
                "        return 'kaggle'\n",
                "    else:\n",
                "        return 'local'\n",
                "\n",
                "ENV = detect_env()\n",
                "print(f\"Detected: {ENV.upper()}\")\n",
                "\n",
                "# Setup theo môi trường\n",
                "if ENV == 'local':\n",
                "    # Local: Import trực tiếp từ repo\n",
                "    # Giả sử đang ở competitions/titanic/notebooks/\n",
                "    repo_root = Path.cwd().parent.parent.parent\n",
                "    if str(repo_root) not in sys.path:\n",
                "        sys.path.insert(0, str(repo_root))\n",
                "    \n",
                "    from core import setup_env\n",
                "    env = setup_env.setup()\n",
                "    \n",
                "else:\n",
                "    # Cloud: Download setup_env.py từ GitHub\n",
                "    import requests\n",
                "    import subprocess\n",
                "    \n",
                "    CORE_URL = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/{BRANCH}/core\"\n",
                "    \n",
                "    # Download setup_env.py\n",
                "    print(\"Downloading setup_env.py...\")\n",
                "    response = requests.get(f\"{CORE_URL}/setup_env.py\")\n",
                "    with open(\"setup_env.py\", \"w\") as f:\n",
                "        f.write(response.text)\n",
                "    \n",
                "    # Import và setup\n",
                "    import setup_env\n",
                "    env = setup_env.setup(GITHUB_USER, REPO_NAME)\n",
                "\n",
                "# Hiển thị thông tin môi trường\n",
                "env.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration\n",
                "\n",
                "Cấu hình chung cho notebook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import accuracy_score\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Configuration class\n",
                "class CFG:\n",
                "    # Random seed cho reproducibility\n",
                "    seed = 42\n",
                "    \n",
                "    # Cross-validation\n",
                "    n_folds = 5\n",
                "    \n",
                "    # Target column\n",
                "    target_col = 'Survived'\n",
                "    \n",
                "    # Data paths (tự động set theo môi trường)\n",
                "    if ENV == 'kaggle':\n",
                "        data_dir = Path('/kaggle/input/titanic')\n",
                "    else:\n",
                "        data_dir = Path.cwd().parent / 'data'\n",
                "    \n",
                "    train_path = data_dir / 'train.csv'\n",
                "    test_path = data_dir / 'test.csv'\n",
                "    submission_path = Path.cwd().parent / 'submissions' / 'submission.csv'\n",
                "\n",
                "# Set random seeds\n",
                "def seed_everything(seed):\n",
                "    np.random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "\n",
                "seed_everything(CFG.seed)\n",
                "\n",
                "# Display config\n",
                "print(\"Configuration:\")\n",
                "print(f\"  - Seed: {CFG.seed}\")\n",
                "print(f\"  - N Folds: {CFG.n_folds}\")\n",
                "print(f\"  - Data Dir: {CFG.data_dir}\")\n",
                "print(f\"  - Train: {CFG.train_path.exists()}\")\n",
                "print(f\"  - Test: {CFG.test_path.exists()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load datasets\n",
                "train = pd.read_csv(CFG.train_path)\n",
                "test = pd.read_csv(CFG.test_path)\n",
                "\n",
                "print(f\"Train shape: {train.shape}\")\n",
                "print(f\"Test shape: {test.shape}\")\n",
                "\n",
                "# Display first rows\n",
                "train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic info\n",
                "print(\"=\" * 50)\n",
                "print(\"TRAIN DATA INFO\")\n",
                "print(\"=\" * 50)\n",
                "print(train.info())\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"STATISTICAL SUMMARY\")\n",
                "print(\"=\" * 50)\n",
                "print(train.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Missing values\n",
                "missing = train.isnull().sum()\n",
                "missing = missing[missing > 0].sort_values(ascending=False)\n",
                "\n",
                "if len(missing) > 0:\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    missing.plot(kind='barh')\n",
                "    plt.title('Missing Values in Train Data')\n",
                "    plt.xlabel('Count')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    print(\"\\nMissing Values:\")\n",
                "    print(missing)\n",
                "else:\n",
                "    print(\"No missing values!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Count plot\n",
                "train[CFG.target_col].value_counts().plot(kind='bar', ax=axes[0])\n",
                "axes[0].set_title('Survived Count')\n",
                "axes[0].set_xlabel('Survived (0=No, 1=Yes)')\n",
                "axes[0].set_ylabel('Count')\n",
                "\n",
                "# Pie chart\n",
                "train[CFG.target_col].value_counts().plot(kind='pie', autopct='%1.1f%%', ax=axes[1])\n",
                "axes[1].set_title('Survived Distribution')\n",
                "axes[1].set_ylabel('')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nSurvival Rate: {train[CFG.target_col].mean():.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_features(df):\n",
                "    \"\"\"Tạo các features mới từ dữ liệu gốc\"\"\"\n",
                "    df = df.copy()\n",
                "\n",
                "    # 1. FamilySize = SibSp + Parch + 1\n",
                "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
                "\n",
                "    # 2. IsAlone\n",
                "    df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n",
                "\n",
                "    # 3. Extract Title from Name\n",
                "    df[\"Title\"] = df[\"Name\"].str.extract(\" ([A-Za-z]+)\\\\.\", expand=False)\n",
                "\n",
                "    # 4. Group rare titles\n",
                "    df[\"Title\"] = df[\"Title\"].replace(\n",
                "        [\n",
                "            \"Lady\",\n",
                "            \"Countess\",\n",
                "            \"Capt\",\n",
                "            \"Col\",\n",
                "            \"Don\",\n",
                "            \"Dr\",\n",
                "            \"Major\",\n",
                "            \"Rev\",\n",
                "            \"Sir\",\n",
                "            \"Jonkheer\",\n",
                "            \"Dona\",\n",
                "        ],\n",
                "        \"Rare\",\n",
                "    )\n",
                "    df[\"Title\"] = df[\"Title\"].replace(\"Mlle\", \"Miss\")\n",
                "    df[\"Title\"] = df[\"Title\"].replace(\"Ms\", \"Miss\")\n",
                "    df[\"Title\"] = df[\"Title\"].replace(\"Mme\", \"Mrs\")\n",
                "\n",
                "    # 5. Age groups\n",
                "    df[\"AgeGroup\"] = pd.cut(\n",
                "        df[\"Age\"],\n",
                "        bins=[0, 12, 18, 35, 60, 100],\n",
                "        labels=[\"Child\", \"Teen\", \"Adult\", \"Middle\", \"Senior\"],\n",
                "    )\n",
                "\n",
                "    # 6. Fare groups\n",
                "    df[\"FareGroup\"] = pd.qcut(\n",
                "        df[\"Fare\"], q=4, labels=[\"Low\", \"Medium\", \"High\", \"VeryHigh\"]\n",
                "    )\n",
                "\n",
                "    # 7. Has Cabin\n",
                "    df[\"HasCabin\"] = df[\"Cabin\"].notna().astype(int)\n",
                "\n",
                "    return df\n",
                "\n",
                "\n",
                "# Apply feature engineering\n",
                "print(\"Creating features...\")\n",
                "train_fe = create_features(train)\n",
                "test_fe = create_features(test)\n",
                "print(\"Feature engineering complete!\")\n",
                "\n",
                "# Display new features\n",
                "print(\"\\nNew features:\")\n",
                "print(train_fe[[\"FamilySize\", \"IsAlone\", \"Title\", \"AgeGroup\", \"HasCabin\"]].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "\n",
                "def preprocess_data(train_df, test_df, target_col=\"Survived\"):\n",
                "    \"\"\"Xử lý missing values và encoding\"\"\"\n",
                "\n",
                "    # Separate target\n",
                "    y_train = train_df[target_col].copy() if target_col in train_df.columns else None\n",
                "\n",
                "    # Drop target and unnecessary columns\n",
                "    drop_cols = [target_col, \"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
                "    X_train = train_df.drop(\n",
                "        columns=[col for col in drop_cols if col in train_df.columns]\n",
                "    )\n",
                "    X_test = test_df.drop(columns=[col for col in drop_cols if col in test_df.columns])\n",
                "\n",
                "    # Handle missing values\n",
                "    # Age: fill with median by Pclass and Sex\n",
                "    for df in [X_train, X_test]:\n",
                "        for pclass in [1, 2, 3]:\n",
                "            for sex in [\"male\", \"female\"]:\n",
                "                mask = (df[\"Pclass\"] == pclass) & (df[\"Sex\"] == sex)\n",
                "                median_age = X_train.loc[\n",
                "                    (X_train[\"Pclass\"] == pclass) & (X_train[\"Sex\"] == sex), \"Age\"\n",
                "                ].median()\n",
                "                df.loc[mask & df[\"Age\"].isna(), \"Age\"] = median_age\n",
                "\n",
                "    # Embarked: fill with mode\n",
                "    embarked_mode = X_train[\"Embarked\"].mode()[0]\n",
                "    X_train[\"Embarked\"].fillna(embarked_mode, inplace=True)\n",
                "    X_test[\"Embarked\"].fillna(embarked_mode, inplace=True)\n",
                "\n",
                "    # Fare: fill with median\n",
                "    fare_median = X_train[\"Fare\"].median()\n",
                "    X_test[\"Fare\"].fillna(fare_median, inplace=True)\n",
                "\n",
                "    # Fill AgeGroup and FareGroup if they exist\n",
                "    for col in [\"AgeGroup\", \"FareGroup\"]:\n",
                "        if col in X_train.columns:\n",
                "            mode_val = X_train[col].mode()[0]\n",
                "            X_train[col].fillna(mode_val, inplace=True)\n",
                "            if col in X_test.columns:\n",
                "                X_test[col].fillna(mode_val, inplace=True)\n",
                "\n",
                "    # Encode categorical variables\n",
                "    label_encoders = {}\n",
                "    cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n",
                "\n",
                "    for col in cat_cols:\n",
                "        le = LabelEncoder()\n",
                "        # Fit on combined data to ensure same encoding\n",
                "        combined = pd.concat([X_train[col], X_test[col]])\n",
                "        le.fit(combined.astype(str))\n",
                "\n",
                "        X_train[col] = le.transform(X_train[col].astype(str))\n",
                "        X_test[col] = le.transform(X_test[col].astype(str))\n",
                "        label_encoders[col] = le\n",
                "\n",
                "    return X_train, X_test, y_train, label_encoders\n",
                "\n",
                "\n",
                "# Apply preprocessing\n",
                "print(\"Preprocessing data...\")\n",
                "X_train, X_test, y_train, encoders = preprocess_data(train_fe, test_fe)\n",
                "print(\"Preprocessing complete!\")\n",
                "print(f\"\\nTrain shape: {X_train.shape}\")\n",
                "print(f\"Test shape: {X_test.shape}\")\n",
                "print(f\"Features: {list(X_train.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Modeling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "\n",
                "# Initialize models\n",
                "models = {\n",
                "    \"LogisticRegression\": LogisticRegression(random_state=CFG.seed, max_iter=1000),\n",
                "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=CFG.seed),\n",
                "    \"GradientBoosting\": GradientBoostingClassifier(\n",
                "        n_estimators=100, random_state=CFG.seed\n",
                "    ),\n",
                "    \"XGBoost\": XGBClassifier(\n",
                "        n_estimators=100, random_state=CFG.seed, eval_metric=\"logloss\"\n",
                "    ),\n",
                "    \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=CFG.seed, verbose=-1),\n",
                "}\n",
                "\n",
                "# Cross-validation\n",
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "cv_results = {}\n",
                "print(\"Training models với Cross-Validation...\")\n",
                "\n",
                "for name, model in models.items():\n",
                "    scores = cross_val_score(\n",
                "        model, X_train, y_train, cv=CFG.n_folds, scoring=\"accuracy\"\n",
                "    )\n",
                "    cv_results[name] = scores\n",
                "    print(f\"{name:20s} - CV Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
                "\n",
                "# Train best model on full training data\n",
                "best_model_name = max(cv_results, key=lambda x: cv_results[x].mean())\n",
                "print(f\"\\nBest model: {best_model_name}\")\n",
                "\n",
                "final_model = models[best_model_name]\n",
                "final_model.fit(X_train, y_train)\n",
                "print(\"Model training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance (for tree-based models)\n",
                "if hasattr(final_model, \"feature_importances_\"):\n",
                "    feature_importance = pd.DataFrame(\n",
                "        {\"feature\": X_train.columns, \"importance\": final_model.feature_importances_}\n",
                "    ).sort_values(\"importance\", ascending=False)\n",
                "\n",
                "    print(\"\\nTop 10 Feature Importances:\")\n",
                "    print(feature_importance.head(10))\n",
                "\n",
                "    # Plot\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    feature_importance.head(10).plot(x=\"feature\", y=\"importance\", kind=\"barh\")\n",
                "    plt.title(f\"Top 10 Feature Importances - {best_model_name}\")\n",
                "    plt.xlabel(\"Importance\")\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Cross-validation scores comparison\n",
                "plt.figure(figsize=(12, 6))\n",
                "cv_df = pd.DataFrame(cv_results)\n",
                "cv_df.boxplot()\n",
                "plt.title(\"Cross-Validation Scores by Model\")\n",
                "plt.ylabel(\"Accuracy\")\n",
                "plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions on test set\n",
                "test_predictions = final_model.predict(X_test)\n",
                "\n",
                "# Create submission file\n",
                "submission = pd.DataFrame(\n",
                "    {\"PassengerId\": test[\"PassengerId\"], \"Survived\": test_predictions}\n",
                ")\n",
                "\n",
                "# Save to CSV\n",
                "submission.to_csv(CFG.submission_path, index=False)\n",
                "print(f\"\\nSubmission saved to: {CFG.submission_path}\")\n",
                "print(f\"Submission shape: {submission.shape}\")\n",
                "print(\"\\nFirst few predictions:\")\n",
                "print(submission.head(10))\n",
                "\n",
                "# Display submission statistics\n",
                "print(f\"\\nPredicted survival rate: {test_predictions.mean():.2%}\")\n",
                "print(f\"Total passengers predicted to survive: {test_predictions.sum()}\")\n",
                "print(\n",
                "    f\"Total passengers predicted to die: {len(test_predictions) - test_predictions.sum()}\"\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "kaggle-competitions",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
